{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5s2ZPN34Vna_"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "The **Q-learning algorithm** assumes a discrete observation space. Hence, to solve the Cart-Pole environment using simple Q-learning, for each of the attributes of an agent's state,\n",
        "\n",
        "1. cart position, \n",
        "2. cart velocity, \n",
        "3. pole angle, and \n",
        "4. pole angular velocity,\n",
        "\n",
        "the continuous state values need to be discretized into a fixed number of buckets. For example, with bucket sizes $(1, 1, 6, 3)$ for the $4$-dimensional observation space and a $2$-dimensional action space, the dimensions of the $\\text{Q-table}$ are $1\\times 1\\times 6\\times 3\\times 2$.\n",
        "\n",
        "Q-learning suffers from the curse-of-dimensionality as it requires discrete states to form the $\\text{Q-table}$. The computational complexity of the algorithm increases exponentially with increasing number of buckets and the dimension of the action space. **Deep Q-learning** solves this problem by approximating the Q-value function $Q(s, a)$ with an artificial neural network, called a **Deep Q-network (DQN)** [1]. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PEmbcZfQZQRW"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, glob, shutil\n",
        "import warnings; warnings.filterwarnings(\"ignore\")\n",
        "from tqdm import tqdm\n",
        "from time import time"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**NumPy**: NumPy adds support for large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays. Gym returns the agent's state as a numpy.ndarray. [2]\n",
        "\n",
        "**Matplotlib**: Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations. [3]\n",
        "\n",
        "**TensorFlow**: TensorFlow is a library with a particular focus on training and inference of deep neural networks. We use it to create and train the DQN. [4]\n",
        "\n",
        "**Keras**: Keras is based on minimal structure that provides a clean and easy way to create deep learning models based on TensorFlow.\n",
        "\n",
        "**Gym**: Gym is a standard API for reinforcement learning, and a diverse collection of reference environments. We use it to create the Cart-Pole environment. [5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1vaI_pmHr5-X"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Jasraj\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py:169: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  if LooseVersion(module.__version__) < minver:\n",
            "c:\\Users\\Jasraj\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\version.py:345: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  other = LooseVersion(other)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "import gym; gym.logger.set_level(40)\n",
        "from gym.wrappers import RecordVideo\n",
        "from IPython.display import display, Video\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_video():\n",
        "    mp4list = glob.glob(\"video/*.mp4\")\n",
        "    if len(mp4list) > 0:\n",
        "        display(Video(filename=mp4list[0]))\n",
        "    else: \n",
        "        print(\"Could not find video\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_lCHN4UcaYY"
      },
      "source": [
        "# GPU Setup\n",
        "We check if a GPU is available and set the device accordingly - GPU, if it is available, else CPU. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_uRJ93LesSlD"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/CPU:0'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = \"/device:GPU:0\" if tf.config.list_physical_devices(\"GPU\") else \"/CPU:0\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-Mv9HgOcrXG"
      },
      "source": [
        "# Deep Q-Network\n",
        "\n",
        "We define the DQN as a multilayer perceptron with ReLU activation for the hidden layers. It takes $4$ inputs (dimension of the observation space), and returns a $2$-dimensional output corresponding to the estimated Q-values for each of the $2$ states."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LKlVtLGqr5-e"
      },
      "outputs": [],
      "source": [
        "class Model(Sequential):\n",
        "\n",
        "    '''\n",
        "    neural network used by our agent to estimate Q-values. \n",
        "    '''\n",
        "\n",
        "    def __init__(self, name, in_dim, h_dims, out_dim, batch_size, lr):\n",
        "\n",
        "        '''\n",
        "        initialize the network.\n",
        "        params:\n",
        "            name: name given to the neural network.\n",
        "            in_dim: dimension of the neural network input.\n",
        "            h_dims: list of sizes of hidden layers in the network.\n",
        "            out_dim: dimension of the neural network output.\n",
        "            batch_size: batch size to train the neural network with.\n",
        "            lr: learning rate for Adam optimizer. \n",
        "        return: \n",
        "            neural network with weights initialized.\n",
        "        '''\n",
        "\n",
        "        # initialize the Sequential model class from keras.\n",
        "        super().__init__(name=name)\n",
        "        \n",
        "        # create the model with Adam optimizer.\n",
        "        self.add(Dense(h_dims[0], input_shape=(in_dim,), activation=\"relu\", name=\"hidden_layer_1\"))\n",
        "        for i, h_dim in enumerate(h_dims[1:], 2):\n",
        "            self.add(Dense(h_dim, activation=\"relu\", name=f\"hidden_layer_{i}\"))\n",
        "        self.add(Dense(out_dim, activation=\"linear\", name=\"output_layer\"))\n",
        "        self.compile(loss=\"mse\", optimizer=Adam(learning_rate=lr))\n",
        "        self.summary(); print()\n",
        "        \n",
        "        self.batch_size = batch_size"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ewyWC7F2gsbM"
      },
      "source": [
        "# DQN Training\n",
        "\n",
        "The Q-network needs to be trained to estimate Q-values for a given state and action pair. This is done by minimizing the Mean-Square Error (MSE) loss function,\n",
        "\n",
        "$$\n",
        "L(\\theta_i) = \\mathbb{E}_{(s,a)\\sim P(s,a)}\\left[\\left(Q^*(s,a)-Q(s,a;\\theta_i)\\right)^2\\right]\n",
        "$$\n",
        "\n",
        "where the target Q-value $Q^*(s,a)$ for each iteration $i$ is given by\n",
        "\n",
        "$$\n",
        "Q^*(s,a) = \\mathbb{E}_{s'\\in S} \\left. \\left[ R(s,a) + \\gamma\\max_{a'}Q\\left(s',a';\\theta_{i-1}\\right) \\right| s,a \\right]\n",
        "$$\n",
        "\n",
        "where $R(s,a)$ is the reward for the current state-action pair $(s,a)$ obtained from the environment, $\\gamma$ is the discount factor as in the Bellman equation, and $Q\\left(s',a';\\theta_{iâˆ’1}\\right)$ is the Q-value for the next state obtained using the Q-network weights from the previous iteration.\n",
        "\n",
        "## Experience Replay\n",
        "\n",
        "In incremental update, the network learns from one sample at a time, whereas in batch update, the network weights are updated by back-propogating the averaged loss from a fixed number of samples, called a mini-batch. It has been shown that the network trains faster with a batch update rather than with an incremental weight update method. \n",
        "\n",
        "In experience replay, a random sample of past experiences of the agent is used for training the Q-network. Once a sufficient number of entries are stored in the replay memory, we can train the DQN using a randomly selected batch of samples. The exploration rate, $\\epsilon$, is reduced by a factor after each iteration of training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5ISz2770r5-h"
      },
      "outputs": [],
      "source": [
        "class DQNAgent:\n",
        "\n",
        "    '''\n",
        "    DQN agent used to solve the Cart-Pole environment.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, action_space, gamma, epsilon_max, epsilon_decay, epsilon_min, model, memory_size):\n",
        "\n",
        "        '''\n",
        "        initialize the agent.\n",
        "        params:\n",
        "            action_space: action space for the agent, as returned by the environment.\n",
        "            gamma: discount factor, as defined in the Bellman equation.\n",
        "            epsilon_max: starting value of the exploration rate for the agent.\n",
        "                         this is the rate at which the agent picks a random action.\n",
        "            epsilon_decay: factor used to update exploration rate after each round of training. \n",
        "            epsilon_min: minimum exploration rate for the agent.\n",
        "            model: DQN used to estimate the Q-values.\n",
        "            memory_size: capacity (in terms of number of experiences) of the replay memory.\n",
        "        return:\n",
        "            initialized agent with no memory.\n",
        "        '''\n",
        "\n",
        "        self.action_space = action_space\n",
        "        self.model = model\n",
        "\n",
        "        self.gamma = gamma\n",
        "        self.eps = epsilon_max\n",
        "        self.eps_decay = epsilon_decay\n",
        "        self.eps_min = epsilon_min\n",
        "\n",
        "        self.memory_size = memory_size\n",
        "\n",
        "        # create a memory as a map, where the values are initialized as None, but updated as numpy arrays. \n",
        "        self.memory = {\n",
        "            \"states\": None,\n",
        "            \"actions\": None,\n",
        "            \"rewards\": None,\n",
        "            \"observations\": None,\n",
        "            \"dones\": None,\n",
        "        }\n",
        "\n",
        "\n",
        "    def remember(self, state, action, reward, observation, done):\n",
        "\n",
        "        '''\n",
        "        add an experience to the memory.\n",
        "        params:\n",
        "            state: state, s, from which the action was performed.\n",
        "            action: action, a, that was performed.\n",
        "            reward: reward, R(a,s), received from the environment.\n",
        "            observation: new state, s', as returned by the environment.\n",
        "            done: boolean value indicating if the episode was terminated after this step.\n",
        "        '''\n",
        "\n",
        "        # function to update the memory elements with the new experience.\n",
        "        def update_memory(key, value):\n",
        "            if self.memory[key] is None:\n",
        "                self.memory[key] = value\n",
        "            else:\n",
        "                self.memory[key] = np.concatenate((value, self.memory[key]))[:self.memory_size]\n",
        "\n",
        "        # update the different elements with the new experience.\n",
        "        update_memory(\"states\", state.reshape(1, -1))\n",
        "        update_memory(\"actions\", np.array((action,)).astype(np.int8))\n",
        "        update_memory(\"rewards\", np.array((reward,)))\n",
        "        update_memory(\"observations\", observation.reshape(1, -1))\n",
        "        update_memory(\"dones\", np.array((done,)))\n",
        "\n",
        "\n",
        "    def act(self, state):\n",
        "\n",
        "        '''\n",
        "        explore with probability given by exploration rate, else execute the \n",
        "        action with the maximum Q-value as estimated by the neural network.\n",
        "        params:\n",
        "            state: states, s, in which the agent currently is.\n",
        "        return:\n",
        "            the action, a, the agent should take predicted using the Q-values estimated by the network. \n",
        "        '''\n",
        "\n",
        "        # with probability equal to exploration rate, choose a random action.\n",
        "        if np.random.rand() < self.eps:\n",
        "            return self.action_space.sample()\n",
        "        else:\n",
        "            # else choose the action with the highest Q-value.\n",
        "            with tf.device(device):\n",
        "                return np.argmax(self.model.predict(state.reshape(1, -1), verbose=0)[0])\n",
        "\n",
        "\n",
        "    def replay(self):\n",
        "\n",
        "        '''\n",
        "        replay from the memory and update the network weights.\n",
        "        '''\n",
        "\n",
        "        # if memory does not have enough experiences to form a batch, return.\n",
        "        if self.model.batch_size > self.memory[\"states\"].shape[0]:\n",
        "            return\n",
        "\n",
        "        # pick a random set of indices.\n",
        "        mini_batch = np.random.choice(self.memory[\"states\"].shape[0], self.model.batch_size, replace=False)\n",
        "\n",
        "        # retrieve memory elements.\n",
        "        states = self.memory[\"states\"][mini_batch]\n",
        "        actions = self.memory[\"actions\"][mini_batch]\n",
        "        rewards = self.memory[\"rewards\"][mini_batch]\n",
        "        observations = self.memory[\"observations\"][mini_batch]\n",
        "        dones = self.memory[\"dones\"][mini_batch]\n",
        "\n",
        "        # calculate the predicted Q-values of the current state and the next state.\n",
        "        with tf.device(device):\n",
        "            targets = self.model.predict(states, verbose=0)\n",
        "            obs_preds = self.model.predict(observations, verbose=0)\n",
        "\n",
        "        # calculate the TD-target value.\n",
        "        td_targets = rewards + (1-dones)*self.gamma*np.amax(obs_preds, axis=1)\n",
        "        for i, (action, td_target) in enumerate(zip(actions, td_targets)):\n",
        "            targets[i, action] = td_target\n",
        "\n",
        "        # update the network weights.\n",
        "        with tf.device(device):\n",
        "            self.model.fit(states, targets, batch_size=self.model.batch_size, verbose=0)\n",
        "\n",
        "        # update the exploration rate.\n",
        "        self.eps = max(self.eps*self.eps_decay, self.eps_min)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMU0LR-GTV-A"
      },
      "source": [
        "# Training\n",
        "\n",
        "We train the agent until the average over a certain number of most recent episodes exceeds a threshold value. In each episode, we first initialize the environment randomly, and then sequentially take actions based on the states we are in. After each step, we add the experience to the memory and update the weights of the DQN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8uF4uEufr5-k"
      },
      "outputs": [],
      "source": [
        "def train(env, agent, threshold, avg_over, print_every):\n",
        "\n",
        "    '''\n",
        "    function to train the agent.\n",
        "    params:\n",
        "        env: Cart-Pole environment as given by gym.\n",
        "        agent: our deep Q-learning agent.\n",
        "        threshold: average reward before terminating the training.\n",
        "        avg_over: number of episodes to calculate the average over.\n",
        "        print_every: print the episode results after these number of steps.\n",
        "    return:\n",
        "        a list of rewards from each episode.\n",
        "    '''\n",
        "\n",
        "    # initialize an array to collect results and set episode number to 0.\n",
        "    results, episode, start_time = list(), 0, time()\n",
        "\n",
        "    # iterate until the average reward is at least the threshold value. \n",
        "    while not results or np.mean(results[-avg_over:]) <= threshold:\n",
        "\n",
        "        # update episode number and initialize the environment.\n",
        "        episode += 1\n",
        "        state = np.reshape(env.reset(), (1, -1))\n",
        "        # initialize the number of steps in the episode to 0.\n",
        "        steps, done = 0, False\n",
        "            \n",
        "        # iterate until the episode terminates. \n",
        "        while not done:\n",
        "\n",
        "            # update the number of steps.\n",
        "            steps += 1\n",
        "            # choose an action to perform.\n",
        "            action = agent.act(state)\n",
        "            # get the new state, reward and termination info from the environment.\n",
        "            observation, reward, done, *_ = env.step(action)\n",
        "            reward = reward if not done else -reward\n",
        "\n",
        "            # add the experience to the memory.\n",
        "            agent.remember(state, action, reward, observation, done)\n",
        "            state = observation.copy()\n",
        "            # update the network weights.\n",
        "            agent.replay()\n",
        "\n",
        "        # add the result to the results array.\n",
        "        results.append(steps)\n",
        "        end_time = time() - start_time\n",
        "\n",
        "        # print the result if required.\n",
        "        if episode%print_every == 0:\n",
        "            print(f\"Episode {episode:3.0f}\" + \\\n",
        "                  f\": {np.mean(results[-avg_over:]):6.2f} steps (averaged over last {min(len(results), avg_over):2.0f} episodes)\" + \\\n",
        "                  f\", {end_time//60:2.0f}m {end_time%60:5.2f}s (total running time)\"\n",
        "            )\n",
        "\n",
        "    # print the result of the last episode before training stops.\n",
        "    end_time = time() - start_time\n",
        "    print(\"\\nTraining terminated\")\n",
        "    print(f\"Episode {episode:3.0f}\" + \\\n",
        "          f\": {np.mean(results[-avg_over:]):6.2f} steps (averaged over last {min(len(results), avg_over):2.0f} episodes)\" + \\\n",
        "          f\", {end_time//60:2.0f}m {end_time%60:5.2f}s (total running time)\"\n",
        "    )\n",
        "    \n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sBvUgtCWm2U"
      },
      "source": [
        "# Configurations\n",
        "\n",
        "Here, we define the configurations for the training. Feel free to play around with these values. We pick most hyperparameters as in the original paper on DQN [1]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "j4PPrW6jr5-m"
      },
      "outputs": [],
      "source": [
        "ENV_NAME = \"CartPole-v1\"\n",
        "\n",
        "# training hyperparams.\n",
        "HIDDEN_LAYER_SIZE = 32\n",
        "N_HIDDEN_LAYERS = 2\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "# Q-learning hyperparams. we decay the exploration rate at a linear rate.\n",
        "GAMMA = 0.95\n",
        "EPSILON_MAX = 1.0\n",
        "EPSILON_DECAY = 0.995\n",
        "EPSILON_MIN = 0.01\n",
        "MEMORY_SIZE = 1_000\n",
        "\n",
        "# termination condition hyperparams.\n",
        "# we average over last 50 runs, instead of 100, to (reliably) relax the termination condition.\n",
        "# to compensate for this relaxation, and for higher robustness to noise, we increase the avg reward for terminating from 195 to 225. \n",
        "AVG_OVER = 50\n",
        "AVG_REWARD_FOR_TERMINATION = 225\n",
        "\n",
        "# make the Cart-Pole environment.\n",
        "env = gym.make(\n",
        "    id=ENV_NAME\n",
        ")\n",
        "\n",
        "# path for saving the DQN.\n",
        "save_dir = \"CartPoleDQN\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ksc7oePOaWjs"
      },
      "source": [
        "# Train the Agent\n",
        "\n",
        "We train the agent and plot how the reward evolved over multiple episodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4Z0jQimiaYt4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"CartPoleDQN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hidden_layer_1 (Dense)      (None, 32)                160       \n",
            "                                                                 \n",
            " hidden_layer_2 (Dense)      (None, 32)                1056      \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,282\n",
            "Trainable params: 1,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Episode  10:  20.30 steps (averaged over last 10 episodes),  1m 20.07s (total running time)\n",
            "Episode  20:  15.40 steps (averaged over last 20 episodes),  2m 20.25s (total running time)\n",
            "Episode  30:  22.13 steps (averaged over last 30 episodes),  5m 21.83s (total running time)\n",
            "Episode  40:  35.27 steps (averaged over last 40 episodes), 12m 21.37s (total running time)\n",
            "Episode  50:  40.66 steps (averaged over last 50 episodes), 17m 41.31s (total running time)\n",
            "Episode  60:  46.98 steps (averaged over last 50 episodes), 22m 15.42s (total running time)\n",
            "Episode  70:  66.02 steps (averaged over last 50 episodes), 31m 36.14s (total running time)\n",
            "Episode  80:  95.24 steps (averaged over last 50 episodes), 52m  3.65s (total running time)\n",
            "Episode  90: 144.56 steps (averaged over last 50 episodes), 78m 42.55s (total running time)\n",
            "Episode 100: 178.26 steps (averaged over last 50 episodes), 86m 44.13s (total running time)\n",
            "Episode 110: 211.20 steps (averaged over last 50 episodes), 94m  7.61s (total running time)\n",
            "\n",
            "Training terminated\n",
            "Episode 117: 225.48 steps (averaged over last 50 episodes), 98m 30.57s (total running time)\n"
          ]
        }
      ],
      "source": [
        "# initialize the DQN.\n",
        "model = Model(\n",
        "    name=\"CartPoleDQN\", \n",
        "    in_dim=env.observation_space.shape[0],\n",
        "    h_dims=[HIDDEN_LAYER_SIZE]*N_HIDDEN_LAYERS,\n",
        "    out_dim=env.action_space.n,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    lr=LEARNING_RATE,\n",
        ")\n",
        "\n",
        "# intialize the deep Q-learning agent.\n",
        "agent = DQNAgent( \n",
        "    action_space=env.action_space,\n",
        "    gamma=GAMMA,\n",
        "    epsilon_max=EPSILON_MAX,\n",
        "    epsilon_decay=EPSILON_DECAY,\n",
        "    epsilon_min=EPSILON_MIN,\n",
        "    model=model,\n",
        "    memory_size=MEMORY_SIZE,\n",
        ")\n",
        "\n",
        "# train the agent and collect results.\n",
        "results = train(\n",
        "    env=env, \n",
        "    agent=agent,\n",
        "    threshold=AVG_REWARD_FOR_TERMINATION,\n",
        "    avg_over=AVG_OVER,\n",
        "    print_every=10,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Zm7GzIYYbiE"
      },
      "source": [
        "# Save the DQN Weights\n",
        "\n",
        "To avoid retraining the DQN again and again, we save the weights and can initialize the agent using it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZdtyeA9UYsJZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: CartPoleDQN\\assets\n"
          ]
        }
      ],
      "source": [
        "# if the model weights had been previously saved, delete them.\n",
        "if os.path.isdir(save_dir):\n",
        "    shutil.rmtree(save_dir)\n",
        "\n",
        "# save the weights.\n",
        "agent.model.save(save_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faCUD-1UYsog"
      },
      "source": [
        "# Load the DQN Weights\n",
        "\n",
        "Here, we load the weights back into the DQN, and re-initialize the agent. Note that here we initialize the exploration rate as its minimum possible value assuming that the DQN weights were saved when this minimum was reached. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HaoNTSTAZoe_"
      },
      "outputs": [],
      "source": [
        "# load the DQN.\n",
        "model = load_model(save_dir)\n",
        "\n",
        "# initialize the agent with this DQN.\n",
        "agent = DQNAgent( \n",
        "    action_space=env.action_space,\n",
        "    gamma=GAMMA,\n",
        "    epsilon_max=EPSILON_MIN,\n",
        "    epsilon_decay=EPSILON_DECAY,\n",
        "    epsilon_min=EPSILON_MIN,\n",
        "    model=model,\n",
        "    memory_size=MEMORY_SIZE,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAxNNIXLYROS"
      },
      "source": [
        "# Task 1\n",
        "\n",
        "For Task 1, we can show the observation and chosen action below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Eer3UL0xYW6W"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Observation: [-0.03313689  0.00261254  0.02385543 -0.03744387]\n",
            "Chosen action: 1\n"
          ]
        }
      ],
      "source": [
        "observation = env.reset()\n",
        "action = agent.act(observation)\n",
        "print(f\"Observation: {observation}\")\n",
        "print(f\"Chosen action: {action}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example, we have,\n",
        "$$ \\begin{align*}\n",
        "    \\text{cart position} &=& -&0.03313689 \\\\\n",
        "    \\text{cart velocity} &=& &0.00261254 \\\\\n",
        "    \\text{pole angle} &=& &0.02385543 \\\\\n",
        "    \\text{pole angular velocity} &=& -&0.03744387\n",
        "\\end{align*} $$\n",
        "\n",
        "The action chose by our agent is $1$, or, to move right."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HS6exC6qbIJ1"
      },
      "source": [
        "# Task 2: Demonstrate the effectiveness of the RL agent\n",
        "\n",
        "For this task, we use the agent developed in Task 1 to play the game for $100$ episodes. We record the cumulative reward for each round, and plot it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6G5sNt3gbVYe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [46:28<00:00, 27.89s/it]\n"
          ]
        }
      ],
      "source": [
        "xs, ys = list(), list()\n",
        "for episode in tqdm(range(1, 101)):\n",
        "    state = env.reset()\n",
        "    steps, done = 0, False    \n",
        "    while not done:\n",
        "        steps += 1\n",
        "        action = agent.act(state)\n",
        "        state, _, done, *_ = env.step(action)\n",
        "    xs.append(episode); ys.append(steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "avg_reward = np.mean(ys)\n",
        "\n",
        "FONTDICT = {\n",
        "    \"family\": \"serif\", \n",
        "    \"color\" : \"darkred\", \n",
        "    \"weight\": \"normal\", \n",
        "    \"size\"  : 12,\n",
        "}\n",
        "\n",
        "plt.scatter(xs, ys, color=\"blue\", s=10, label=\"Accumulated Rewards\")\n",
        "plt.hlines(avg_reward, 1, len(xs), linestyles=\"dotted\", color=\"green\", label=f\"Average Reward = {avg_reward:.2f}\")\n",
        "plt.hlines(195, 1, len(xs), linestyles=\"dotted\", color=\"red\", label=\"Baseline = 195\")\n",
        "plt.xlabel(\"Episode\", fontdict=FONTDICT, labelpad=12)\n",
        "plt.ylabel(\"Reward\",  fontdict=FONTDICT, labelpad=12)\n",
        "plt.grid()\n",
        "plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Clearly, the agent's average reward is well beyond $195$. In this sequence of $100$ runs, for example, the average reward is $352.02$. Interestingly, the agent receives the maximum reward for a lot of episodes (indicaed by points with $y=500$)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wFq0924XeQxD"
      },
      "source": [
        "# Task 3: Render one episode played by the agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-zjMlSMCeWnd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<video src=\"video\\rl-video-episode-0.mp4\" controls  >\n",
              "      Your browser does not support the <code>video</code> element.\n",
              "    </video>"
            ],
            "text/plain": [
              "<IPython.core.display.Video object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "env = RecordVideo(gym.make(\"CartPole-v1\"), \"./video\")\n",
        "observation = env.reset()\n",
        "while True:\n",
        "    env.render()\n",
        "    action = agent.act(observation)\n",
        "    observation, reward, done, info = env.step(action) \n",
        "    if done: \n",
        "      break;    \n",
        "env.close()\n",
        "show_video()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, we see that the agent finds it hard to stay in the middle of the frame, but when it approaches the frame, it tries very hard to avoid going past it. My analysis (based on multiple replays) shows that the agent has learnt well to balance the pole, but has a hard time staying within the bounds of the frame."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmD9hWegEwAm"
      },
      "source": [
        "# References\n",
        "\n",
        "**[1]** Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D., & Riedmiller, M. A. (2013). Playing Atari with Deep Reinforcement Learning. CoRR, abs/1312.5602. Retrieved from http://arxiv.org/abs/1312.5602.\n",
        "\n",
        "**[2]** Harris, C. R., Millman, K. J., van der Walt, S. J., Gommers, R., Virtanen, P., Cournapeau, D., Wieser, E., Taylor, J., Berg, S., Smith, N. J., Kern, R., Picus, M., Hoyer, S., van Kerkwijk, M. H., Brett, M., Haldane, A., FernÃ¡ndez del RÃ­o, J., Wiebe, M., Peterson, P., GÃ©rard-Marchant, P., Sheppard, K., Reddy, T., Weckesser, W., Abbasi, H., Gohlke, C., & Oliphant, T. E. (2020). Array programming with NumPy. Nature 585, 357â€“362 (2020). DOI: 10.1038/s41586-020-2649-2.\n",
        "\n",
        "**[3]** Hunter, J. D. (2007). Matplotlib: A 2D graphics environment. Computing in Science & Engineering, 9(3), 90â€“95. DOI: 10.1109/MCSE.2007.55\n",
        "\n",
        "**[4]** Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G. S., Davis, A., Dean, J., Devin, M., Ghemawat, S., Goodfellow, I., \n",
        "Harp, A., Irving, G., Isard, M., Jia, Y., Jozefowicz, R., Kaiser, L., Kudlur, M., Levenberg, J., Mane, D., Monga, R., Moore, S., Murray, D., Olah, C., Schuster, M., Shlens, J., Steiner, B., Sutskever, I., Talwar, K., Tucker, P., Vanhoucke, V., Vasudevan, V., Viegas, F., Vinyals, O., Warden, P., \n",
        "Wattenberg, M., Wicke, M., Yu, Y., & Zheng, X. (2015). TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems. Retrieved from https://www.tensorflow.org/.\n",
        "\n",
        "**[5]** Brockman, G., Cheung, V., Pettersson, L., Schneider, J., Schulman, J., Tang, J., & Zaremba, W. (2016). OpenAI Gym. CoRR, abs/1606.01540. Retrieved from http://arxiv.org/abs/1606.01540."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
